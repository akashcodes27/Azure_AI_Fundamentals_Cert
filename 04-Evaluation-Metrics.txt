Evaluation Metrics:

Performance/Evaluation metrics are used to evaluate different machine learning models.

Different Evaluation Metrics are used for different kinds of problems:

1. Classification Metrics: Accuracy, Precision, Recall, F1-score, ROC, AUC 
2. Regression Metrics: MSE, RMSE, MAE
3. Ranking Metrics: MRR, DCG, NDCG 
4. Statistical Metrics: Correlation 
5. Computer Vision Metrics: PSNR, SSIM, IoU 
6. NLP Metrics: Perplexity, BLEU, METEOR, ROUGE 
7. Deep Learning Related Metrics: Inception Score, Franchet Inception Distance 

There are 2 main categories of Evaluation Metrics:
Internal Metrics: 
External Metrics: 


One very popular Evaluation Metric: Confusion Matrix 
Confusion Matrix gives us 4 values: True Positives, True Negatives, False Positives, False Negatives 
Y-Axis: Ground Truth  [True, False]
X-axis: Prediction Labels/variables  [Positive , Negative]

X and y Axis are interchangable 
It compares Ground Truth with Prediction Variables to give us 4 kinds of evaluation results. 

We usually compare 2 classes. One is assumed Positive, 2nd is assumed Negative 
YES heart disease: Positive 
No heart disease: Negative 

True Positive: Prediction says Positive, Ground Truth is True 
Predicted YES heart Disease, Ground Truth YES heart Disease 

True Negative: Prediction NO heart disease, Ground Truth YES heart disease 

False Postive: Predicted YES heart diease, Ground Truth No Heart Disease 

The matrix need not always be 2x2, it can also be 2x3 (when we have more than 2 categories or classes)
Just Remember 
True/False (Tells us Ground Truth)
Positive/Negative (Tells us Prediction Output)